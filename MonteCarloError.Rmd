---
title: "Propagating Monte Carlo Error"
author: "Team A7"
date: "11/29/2018"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)

# Set up my table with provided data
mytab <- read_tsv("classA7.dat", col_names = FALSE)
mytab <- t(apply(mytab, c(1, 2), function(x) eval(parse(text = x))))
colnames(mytab) <- c("X", "Y")
rownames(mytab) <- NULL
```

The functions we are using to generate the fake data are:
1. f1(x) = -2 + 3x
2. f2(x) = 3
3. f3(x) = 6x^2 + 3x + 3
4. f4(x) = 10x + 3
5. f5(x) = -4x - 6

```{r data-gen, echo=FALSE}
f1 <- function(x) -2 + (3*x)
f2 <- function(x) 3
f3 <- function(x) (6*(x**2)) + (3*x) + 3
f4 <- function(x) (10*x) + 3
f5 <- function(x) (-4 * x) - 6

makeFakeData <- function(f) {
    f(mytab[,1]) + rnorm(n = length(mytab[,1]), mean = 0, sd = 1)
}
```
Generation and plotting of the 1000 c0 and c1 values from fake data
```{r linear-fit, echo=FALSE}
funclist <- list(f1, f2, f3, f4, f5)
means_slopes <- integer(length(funclist))
means_intercepts <- integer(length(funclist))
sd_slopes <- integer(length(funclist))
sd_intercepts <- integer(length(funclist))

#print.noquote(funclist[1])
func_ind <- 1
for (fn in funclist) {
  dat = matrix(nrow = 1000, ncol = 2)
  for ( k in 1:1000 ) {
    fakedat <- makeFakeData(fn)
    dat[k,] <- coef(lm( fakedat ~ mytab[,1] ))
  }

  colnames(dat) <- c("Intercept", "Slope")
  if (func_ind < 3) {
    plot(dat)
    densities <- density(dat[,"Intercept"])
    hist(dat[,"Intercept"], freq = FALSE,  main = "Density plot for y-intercept", xlim = c(min(fakedat), max(fakedat)))
    lines(densities)
    abline(a=0, b = 0)
    print.noquote(paste("Function number", func_ind))
    
    densities <- density(dat[,"Slope"])
    hist(dat[,"Slope"], freq = FALSE,  main = "Density plot for slope")
    lines(densities)
    abline(a=0, b = 0)
    print.noquote(paste("Function number", func_ind))
  }
  
  means_intercepts[func_ind] <- mean(dat[,"Intercept"])
  means_slopes[func_ind] <- mean(dat[,"Slope"])
  sd_intercepts[func_ind] <- sd(dat[,"Intercept"])
  sd_slopes[func_ind] <- sd(dat[,"Slope"])
  print.noquote(paste("Mean of the intercept:", means_intercepts[func_ind]))
  print.noquote(paste("Variance of the intercept:", means_slopes[func_ind]))
  print.noquote(paste("Mean of the slope:", sd_slopes[func_ind]))
  print.noquote(paste("Variance of the slope:", sd_intercepts[func_ind]))
  print.noquote("")
 
  
  func_ind <- func_ind + 1
}

```

Conclusion: 
The bell shape historiogram indicated that the values of c0 and c1 are normaly distributed.

Calculation of the standard deviation and mean value of c0 and c1 for every function.
We plotted the values found for analyzing the influence of f(x) on mean and variance.

``` {r comparison-charts, echo=FALSE}
function_num <- 1:length(sd_slopes)
plot(sd_slopes ~ function_num, type = 'l', ylim = c(0, max(sd_slopes)), main = "Standard deviation of slopes")
plot(sd_intercepts ~ function_num, type = 'l', ylim =  c(0, max(sd_intercepts)), main = "Standard deviation of y-intercepts")
plot(means_slopes ~ function_num, type = 'l', main = "Means of slopes")
plot(means_intercepts ~ function_num, type = 'l', main = "Means of y-intercepts")
```

Conclusion:
Mean depends on f(x)
Variencec does not.

We now calculated the covarience of c0 and c1. Since this value is related to the variences, we know that the choice of f(x) will not influence the result.

``` {r covariance-calc, echo=FALSE}
covariance <- cov(dat[,"Slope"], dat[,"Intercept"])
print(paste("Covariance between slope and intercept", covariance))
```

Conclusion:
The value found for the convariance is neglectible, and so the values of c0 and c1 are independent.

From the covarience and varience values found we found the formula for the varience of the linear model, depending on the choice of x.

``` {r variance-calc, echo=FALSE}
realdat_coefs <- coef( lm( mytab[,2] ~ mytab[,1]) )

Vc0 <- round(mean(sd_intercepts)**2, 6)
Vc1<- round(mean(sd_slopes)**2, 6)
print.noquote(paste0("V(f(x)) = ", Vc0, " + ", Vc1, "x^2 + ", "0"))
``` 

From the previous variance formula, we calculated the 90% confidence interval for the linear model.
We plotted the interval together with the best fit linear model and the original data.

``` {r confidence-interval, echo=FALSE}
bottom_int <- realdat_coefs[1] + (realdat_coefs[2] * mytab[,1]) + (1.65 * sqrt(Vc0 + Vc1 * (mytab[,1]**2) ))
top_int <- realdat_coefs[1] + (realdat_coefs[2] * mytab[,1]) - (1.65 * sqrt(Vc0 + Vc1 * (mytab[,1]**2) ))

plot( mytab[,1], bottom_int, type = 'l', col = "red")
abline(lm( mytab[,2] ~ mytab[,1]))
lines( mytab[,1], top_int, col = "red")
points(mytab[,1], mytab[,2])
```

# Conclusion
